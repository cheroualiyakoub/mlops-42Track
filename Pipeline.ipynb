{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c15ad4d-0c85-4a67-93b7-42cf9136790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn \n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b647db-cf68-461a-9b25-7804e255ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Reads the CSV file and returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        if df.empty:\n",
    "            raise ValueError(\"üö® Data loaded but is empty.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"‚ùå Data file not found at specified path.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Unexpected error while loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0636c62-05ca-4892-83dc-5e1f43754889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, y, test_size=0.15, val_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the DataFrame into train, validation, and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(df, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    val_relative_size = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_relative_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1594fe0-e612-4315-b9a3-3a4cad370517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.cols_to_drop = ['instant', 'dteday', 'registered', 'casual']\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "      \n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self.initial_clean_data(X)\n",
    "    \n",
    "    def initial_clean_data(self, df):\n",
    "        df_clean = df.copy()\n",
    "        return df_clean.drop(columns=self.cols_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22511524-79f3-4405-a4f2-375145201515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFEFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features, estimator=None):\n",
    "        self.n_features = n_features\n",
    "        self.estimator = estimator\n",
    "        self.selected_features = None\n",
    "        self.selector = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.estimator is None:\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            self.estimator = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "        \n",
    "        self.selector = RFE(estimator=self.estimator, n_features_to_select=self.n_features)\n",
    "        self.selector.fit(X, y)\n",
    "        \n",
    "        self.selected_features = X.columns[self.selector.support_].tolist()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "            \n",
    "        if set(self.selected_features).issubset(set(X.columns)):\n",
    "            return X[self.selected_features]\n",
    "        else:\n",
    "            return self.selector.transform(X)\n",
    "    \n",
    "    def get_feature_names_out(self):\n",
    "        return np.array(self.selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b51029b-c87a-4a80-aab4-ab3157652672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Nothing to learn here\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            if col not in X.columns:\n",
    "                raise ValueError(f\"Column '{col}' not found in DataFrame\")\n",
    "            X[col] = X[col].astype('category')\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4212f6d-304d-4447-9803-e6a64eb6d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_first=False):\n",
    "        self.drop_first = drop_first\n",
    "        self.dummy_columns = None  # To store column names from training data\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        dummy_df = pd.get_dummies(X, drop_first=self.drop_first)\n",
    "        self.dummy_columns = dummy_df.columns.tolist()\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        dummy_df = pd.get_dummies(X, drop_first=self.drop_first)\n",
    "        \n",
    "        for col in self.dummy_columns:\n",
    "            if col not in dummy_df.columns:\n",
    "                dummy_df[col] = 0\n",
    "                \n",
    "        return dummy_df.reindex(columns=self.dummy_columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f7f91-d49f-4630-a448-d86a53154b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X_eng = X.copy()\n",
    "        X_eng['new_feature'] = X_eng['a'] / X_eng['b']\n",
    "        return X_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8088d44c-41fa-4780-827f-bb3ca97962e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(pipeline, X, y, target_scaler, model_name):\n",
    "    y_pred = pipeline.predict(X)\n",
    "    \n",
    "    y_pred = np.maximum(y_pred, 0)  # Add safety clamp\n",
    "    \n",
    "    return {\n",
    "        \"mse\": mean_squared_error(y, y_pred),\n",
    "        \"mae\": mean_absolute_error(y, y_pred),\n",
    "        \"r2\": r2_score(y, y_pred),\n",
    "        \"msle\": mean_squared_log_error(y, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "934c66f7-5765-41ce-957a-48bbb69d4fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ full_pipeline with RandomForest logged to MLflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ full_pipeline with XGBoost logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df = read_data(\"./data/hour.csv\")\n",
    "    X = df.drop(columns=['cnt'])\n",
    "    y = df['cnt']\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = data_split(X, y)\n",
    "    mlflow.set_experiment(\"Pipeline experiment\")\n",
    "    \n",
    "    base_models = {\n",
    "        \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Define model configurations\n",
    "    models = {\n",
    "        name: GridSearchCV(\n",
    "            estimator=TransformedTargetRegressor(\n",
    "                regressor=model,\n",
    "                func=np.log1p,\n",
    "                inverse_func=np.expm1\n",
    "            ),\n",
    "            param_grid=param_grid,\n",
    "            cv=5,\n",
    "            scoring=\"neg_mean_squared_error\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        for name, model, param_grid in [\n",
    "            (\"RandomForest\", base_models[\"RandomForest\"], {\n",
    "                \"regressor__n_estimators\": [100, 200],\n",
    "                \"regressor__max_depth\": [None, 10],\n",
    "                \"regressor__min_samples_split\": [2, 5]\n",
    "            }),\n",
    "            (\"XGBoost\", base_models[\"XGBoost\"], {\n",
    "                \"regressor__n_estimators\": [100, 200],\n",
    "                \"regressor__learning_rate\": [0.05, 0.1],\n",
    "                \"regressor__max_depth\": [3, 6]\n",
    "            })\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    pipeline_configs = {\n",
    "        \"full_pipeline\": [\n",
    "            ('cleaner', DataCleaner()),\n",
    "            ('category_converter', CategoricalConverter(columns=['weekday', 'weathersit', 'mnth', 'season'])),\n",
    "            ('dummy_encoder', DummyEncoder()),\n",
    "            ('feature_selector', RFEFeatureSelector(n_features=10)),\n",
    "            ('model', None)\n",
    "        ]\n",
    "        # \"no_categorical\": [\n",
    "        #     ('cleaner', DataCleaner()),\n",
    "        #     ('feature_selector', RFEFeatureSelector(n_features=10)),\n",
    "        #     ('model', None)\n",
    "        # ]\n",
    "    }\n",
    "    \n",
    "    # Loop through pipeline configurations and models\n",
    "    for pipeline_name, pipeline_steps in pipeline_configs.items():\n",
    "        for model_name, model in models.items():\n",
    "            with mlflow.start_run(run_name=f\"{pipeline_name}_{model_name}\"):\n",
    "                # Create a copy of the pipeline steps and fill in the model\n",
    "                current_steps = pipeline_steps.copy()\n",
    "                current_steps[-1] = ('model', model)  # Set the model in the pipeline\n",
    "                \n",
    "                # Create the pipeline\n",
    "                pipeline = Pipeline(current_steps)\n",
    "                \n",
    "                # Fit the pipeline\n",
    "                pipeline.fit(X_train, y_train)\n",
    "                \n",
    "                # Make predictions\n",
    "                y_pred = pipeline.predict(X_val)\n",
    "                \n",
    "                # Evaluate\n",
    "                metrics = evaluate_model(pipeline, X_val, y_val, None, model_name)\n",
    "                \n",
    "                # Log parameters\n",
    "                mlflow.log_param(\"pipeline_config\", pipeline_name)\n",
    "                mlflow.log_param(\"model_name\", model_name)\n",
    "                if 'feature_selector' in dict(pipeline.named_steps):\n",
    "                    feature_selector = pipeline.named_steps['feature_selector']\n",
    "                    mlflow.log_param(\"rfe_selection\", feature_selector.n_features)\n",
    "                mlflow.log_params(pipeline.named_steps['model'].best_params_)\n",
    "                mlflow.log_metrics(metrics)\n",
    "                \n",
    "                # Create signature and log model\n",
    "                signature = infer_signature(X_val, y_pred)\n",
    "                input_example = X_train[:5]\n",
    "                \n",
    "                mlflow.sklearn.log_model(\n",
    "                    pipeline, \n",
    "                    \"model\", \n",
    "                    signature=signature, \n",
    "                    input_example=input_example\n",
    "                )\n",
    "                \n",
    "                print(f\"‚úÖ {pipeline_name} with {model_name} logged to MLflow\")\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "369b1bd4-f02f-4411-9552-d577362b5352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([431.70923 ,  77.08661 ,   6.153729, ..., 318.7845  ,  47.983093,\n",
       "       113.09479 ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22af69f6-f2d3-46f2-89e5-45a5df5740a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Best run ID based on lowest MSLE: bc2c3a21e8314e6e96b22982e5fec961\n",
      "üì¶ Loaded Model Parameters:\n",
      " - rfe_selection: 10\n",
      " - regressor__n_estimators: 200\n",
      " - model_name: XGBoost\n",
      " - pipeline_config: no_categorical\n",
      " - regressor__max_depth: 6\n",
      " - regressor__learning_rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.sklearn\n",
    "\n",
    "experiment_name = \"Pipeline experiment\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if experiment is None:\n",
    "    raise ValueError(f\"Experiment '{experiment_name}' not found!\")\n",
    "\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.msle ASC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "if runs.empty:\n",
    "    raise ValueError(\"No runs found with non-null msle metric.\")\n",
    "\n",
    "best_run_id = runs.iloc[0].run_id\n",
    "print(f\"üîç Best run ID based on lowest MSLE: {best_run_id}\")\n",
    "\n",
    "model_uri = f\"runs:/{best_run_id}/model\"\n",
    "best_pipeline = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "client = MlflowClient()\n",
    "run_data = client.get_run(best_run_id).data\n",
    "\n",
    "print(\"üì¶ Loaded Model Parameters:\")\n",
    "for key, value in run_data.params.items():\n",
    "    print(f\" - {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b67be588-99c7-45e1-96e9-741570766678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([398.66428 ,  88.99932 ,   9.816879, ..., 411.9976  ,  36.117226,\n",
       "       102.66221 ], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_pipeline.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28aa5773-9e73-4a9a-a64a-64e7cd536bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.0, 'mae': 0.0, 'r2': 1.0, 'msle': 0.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(best_pipeline, X_test, y_pred, None, \"best model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a999e9-37cb-4e4a-ba92-5e6d42605f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
