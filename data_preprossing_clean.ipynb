{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1717f391-a20f-4abc-9d75-3143c98172e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "# Statsmodels import for VIF calculation\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn \n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b5fb3-5d30-49ef-8720-0762af5b1596",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ### 1. Data Loading & Basic Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ceba30d3-6235-4e0a-94ef-3eba46cea53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Reads the CSV file and returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "        if df.empty:\n",
    "            raise ValueError(\"üö® Data loaded but is empty.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"‚ùå Data file not found at specified path.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Unexpected error while loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e7846b37-4348-4fcf-a990-96b0c11b5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_infos(df):\n",
    "    \"\"\"\n",
    "    Prints general information and description of the DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"Data info : \\n\")\n",
    "    display(df.info())\n",
    "\n",
    "    print(\"\\n\\nData description: \\n\")\n",
    "    display(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "66946d4e-20da-4061-944c-620ef2bd09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null(df):\n",
    "    \"\"\"\n",
    "    Check and display the number of null values in each column.\n",
    "    \"\"\"\n",
    "    print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec6021-40b1-4093-99dd-02f762678bc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ### 1. Clean data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "19503a29-648e-4627-8e09-c03e3a0a2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intial_clean_data(df):\n",
    "    \"\"\"\n",
    "    Drops unnecessary columns from the DataFrame.\n",
    "    \"\"\"\n",
    "    cols_to_drop = ['instant', 'dteday', 'registered', 'casual']\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901dd97d-ca0d-4664-9d98-c117403bb4f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ### 1. Convert Data type and dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2f4aa02b-0799-48b8-9121-69147de7ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category_type(df, columns):\n",
    "    \"\"\"\n",
    "    Converts specified columns to categorical type.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "        else:\n",
    "            raise KeyError(f\"Column '{col}' not found in DataFrame.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cd970925-4849-452c-9df7-7f1b4024e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dummies(df):\n",
    "    \"\"\"\n",
    "    Converts categorical columns to dummy/indicator variables.\n",
    "    \"\"\"\n",
    "    df = pd.get_dummies(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7fdc579b-5d70-4d37-8096-002febba15b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_columns(df):\n",
    "    \"\"\"\n",
    "    Returns the numeric columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    return df.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d46e615c-8bce-476b-b4b2-31e29e7014d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bool_float(df):\n",
    "    \"\"\"\n",
    "    Converts all boolean columns in a DataFrame to float (0.0 and 1.0).\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with boolean columns converted to float.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include='bool').columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3ef424f8-3316-40f3-bb32-63e06dd05620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_int_float(df):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include='int').columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e7745-f46c-4d4e-8b15-aa862c3d7ed0",
   "metadata": {},
   "source": [
    "# ### 1. Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "762a4aad-8530-4f03-bddc-b7ffa93f6900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispayl_histplot(df):\n",
    "    \"\"\"\n",
    "    Displays histograms for all numeric columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    \n",
    "    n_cols = 4  \n",
    "    n_rows = math.ceil(len(numeric_columns) / n_cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows))\n",
    "    \n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, column in enumerate(numeric_columns):\n",
    "        sns.histplot(df[column], kde=True, ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {column}')\n",
    "        \n",
    "    for i in range(len(numeric_columns), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f57b595a-39c8-4b6a-ad62-933ce275e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_barplot(df, column):\n",
    "    \"\"\"\n",
    "    Displays barplot for a specific column.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (10,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(x=column, y='cnt', data=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "de1da593-0f5a-4cae-9e9e-06a17272042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_violinplot(df):\n",
    "    \"\"\"\n",
    "    Displays violin plot for multiple features against the 'cnt' column.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    columns_to_plot = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', \n",
    "                       'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "    \n",
    "    for idx, col in enumerate(columns_to_plot):\n",
    "        plt.subplot(4, 3, idx + 1)\n",
    "        if df[col].nunique() < 10:\n",
    "            sns.violinplot(x=col, y='cnt', data=df)\n",
    "        else:\n",
    "            sns.scatterplot(x=col, y='cnt', data=df, alpha=0.5)\n",
    "        plt.title(f'{col} vs cnt')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "761f26c2-35a4-4427-8bc5-ca9808243857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_corelation(df):\n",
    "    \"\"\"\n",
    "    Displays the correlation heatmap between numerical features.\n",
    "    \"\"\"\n",
    "    corr_matrix = df.corr(numeric_only=True)\n",
    "    plt.figure(figsize=(25, 20))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation Between Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e38eb8e3-7c13-4a60-9315-6337bf5abe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, y, test_size=0.15, val_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the DataFrame into train, validation, and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(df, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    val_relative_size = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_relative_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf296475-e44f-438d-95be-0a797dee2055",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ### 1. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf8d24-6e3b-4af5-8bd3-7de07cb13ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "046c5012-ac5b-4d06-807a-e0c84dde8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_rfe(X_train_scaled, y_train_scaled, n_features=15):\n",
    "    \"\"\"\n",
    "    Selects features using Recursive Feature Elimination (RFE).\n",
    "    \"\"\"\n",
    "    lr_rfe = LinearRegression()\n",
    "    lr_rfe.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    rfe = RFE(estimator=lr_rfe, n_features_to_select=n_features)\n",
    "    rfe = rfe.fit(X_train_scaled, y_train_scaled)\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        rfe.transform(X_train_scaled),\n",
    "        columns=X_train_scaled.columns[rfe.support_],\n",
    "        index=X_train_scaled.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dfd1ee01-fb2e-4c8a-9e86-e08ab9c79919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(X_train_rfe):\n",
    "    \"\"\"\n",
    "    Calculates Variance Inflation Factor (VIF) for each feature.\n",
    "    \"\"\"\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Features'] = X_train_rfe.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(X_train_rfe.values, i) for i in range(X_train_rfe.shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'], 2)\n",
    "    return vif.sort_values(by=\"VIF\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f58057ca-4479-4011-a97a-7cb168da7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_rfe(rfe, df):\n",
    "       return pd.DataFrame(\n",
    "        rfe.transform(df),\n",
    "        columns=df.columns[rfe.support_],\n",
    "        index=df.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623b0db-f719-4ac8-9a91-9d10b260b7d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ### 1. Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e8ff8ab7-309f-4679-9c85-a5fb37fa01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(X):\n",
    "    feature_scaler = MinMaxScaler()  \n",
    "    X_scaled = feature_scaler.fit_transform(X) \n",
    "    return feature_scaler, X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "36ab416e-4b65-4b7f-97c9-c1b0753b086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_target(y):\n",
    "    target_scaler = MinMaxScaler()  \n",
    "    y_scaled = target_scaler.fit_transform(y.values.reshape(-1, 1)) \n",
    "    return target_scaler, y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c6112941-50b4-49e3-9044-48a01d820200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale_features(scaler, X_scaled):\n",
    "    X_unscaled = scaler.inverse_transform(X_scaled)\n",
    "    return X_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "32aa8323-b33d-4498-b5cc-6746b7cdd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale_target(scaler, y_scaled):\n",
    "    y_unscaled = scaler.inverse_transform(y_scaled)\n",
    "    return y_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d8ce4e60-2f58-4e58-a3e7-721c7ba3d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    \"\"\"\n",
    "    Saves the trained model to a file.\n",
    "    \"\"\"\n",
    "    import joblib\n",
    "    joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a6c32c01-cd40-499e-b14c-b008fdf41721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Loads a saved model from a file.\n",
    "    \"\"\"\n",
    "    import joblib\n",
    "    return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f250e5-67ac-4b77-9817-fe9b8ec17085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ### 1. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "48178c29-4ed1-4b24-a338-8fd2eda44fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(X_train_scaled, y_train_scaled):\n",
    "    \"\"\"\n",
    "    Trains a Linear Regression model and evaluates it.\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d5913f13-06e7-4680-bd6d-036c0d444a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_val, y_val, target_scaler, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model using RMSLE, RMSE, NRMSE, and Relative Error.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained regression model with a predict method\n",
    "    - X_val: Validation features\n",
    "    - y_val: True target values (scaled)\n",
    "    - target_scaler: Scaler used to inverse transform target values\n",
    "    - model_name: Optional name for the model\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict and reshape\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_array = np.array(y_pred).reshape(-1, 1)\n",
    "    y_val_array = np.array(y_val).reshape(-1, 1)\n",
    "\n",
    "    # Inverse transform predictions and targets\n",
    "    y_pred_original = target_scaler.inverse_transform(y_pred_array)\n",
    "    y_test_original = target_scaler.inverse_transform(y_val_array)\n",
    "\n",
    "    # Clip predictions to avoid negative values\n",
    "    y_pred_clipped = np.clip(y_pred_original, 0, None)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test_original, y_pred_clipped))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_clipped))\n",
    "    nrmse = rmse / (y_test_original.max() - y_test_original.min())\n",
    "    relative_error = rmse / y_test_original.mean()\n",
    "\n",
    "    # Print or log\n",
    "    print(f\"üìä Evaluation Results for {model_name}:\")\n",
    "    print(f\" - RMSLE: {rmsle:.4f}\")\n",
    "    print(f\" - RMSE: {rmse:.4f}\")\n",
    "    print(f\" - Normalized RMSE: {nrmse:.2%}\")\n",
    "    print(f\" - Relative Error: {relative_error:.2%}\")\n",
    "\n",
    "    return {\n",
    "        \"rmsle\": rmsle,\n",
    "        \"rmse\": rmse,\n",
    "        \"nrmse\": nrmse,\n",
    "        \"relative_error\": relative_error\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901c508-831f-4c34-ae82-5a9809279dca",
   "metadata": {},
   "source": [
    "# ### 1. Run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cefac560-138f-4d63-a0c0-e6231c1d6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    # Load and clean data\n",
    "    df = read_data(\"./data/hour.csv\")\n",
    "    df_cleaned = intial_clean_data(df)\n",
    "\n",
    "    # Visualize data\n",
    "    # dispayl_histplot(df_cleaned)\n",
    "    # display_violinplot(df_cleaned)\n",
    "    # display_corelation(df_cleaned)\n",
    "\n",
    "    # Convert to category and one-hot encode\n",
    "    df_cleaned = convert_to_category_type(df_cleaned, ['weekday', 'weathersit', 'mnth', 'season'])\n",
    "    df_cleaned = convert_dummies(df_cleaned)\n",
    "    df_cleaned = convert_bool_float(df_cleaned)\n",
    "    df_cleaned = convert_int_float(df_cleaned)\n",
    "\n",
    "    X = df_cleaned.drop(columns=['cnt'])\n",
    "    y = df_cleaned['cnt']\n",
    "\n",
    "    df_ref = feature_selection_rfe(X, y, 32)\n",
    "    \n",
    "    # Split data into train, validation, and test sets\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = data_split(df_ref, y)\n",
    "\n",
    "    \n",
    "    # Scale features and target\n",
    "    feature_scaler, X_train_scaled = scale_features(X_train)\n",
    "    target_scaler, y_train_scaled = scale_target(y_train)\n",
    "    \n",
    "    # Train model\n",
    "    model = train_linear_model(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ecf79965-2d61-4c14-b39f-2cd24bd8e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation Results for linearRegression:\n",
      " - RMSLE: 4.3519\n",
      " - RMSE: 246416.4211\n",
      " - Normalized RMSE: 27.44%\n",
      " - Relative Error: 136.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:281: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return X @ coef_.T + self.intercept_\n",
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:281: RuntimeWarning: overflow encountered in matmul\n",
      "  return X @ coef_.T + self.intercept_\n",
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:281: RuntimeWarning: invalid value encountered in matmul\n",
      "  return X @ coef_.T + self.intercept_\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_model(model, X_val, y_val, target_scaler, model_name=\"linearRegression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7a8a213c-3c7c-4327-b890-487adf8b21b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/level3/mlops42/mlruns/389502738792437896', creation_time=1746704143441, experiment_id='389502738792437896', last_update_time=1746704143441, lifecycle_stage='active', name='Bike sharing', tags={}>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Bike sharing\")  # Name your experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f2bde480-3ef4-404a-8533-2b1dc28a1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "models ={\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=100),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e8c0dd4e-862e-460d-a8a1-5f32ca48c2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: overflow encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: invalid value encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: divide by zero encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: overflow encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n",
      "/Users/level3/mlops42/myenv/lib/python3.9/site-packages/sklearn/linear_model/_base.py:279: RuntimeWarning: invalid value encountered in matmul\n",
      "  return X @ coef_ + self.intercept_\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation Results for LinearRegression:\n",
      " - RMSLE: 2.5298\n",
      " - RMSE: 132243.6623\n",
      " - Normalized RMSE: 14.73%\n",
      " - Relative Error: 73.01%\n",
      "üìä Evaluation Results for RandomForest:\n",
      " - RMSLE: 0.3836\n",
      " - RMSE: 41535.4810\n",
      " - Normalized RMSE: 4.63%\n",
      " - Relative Error: 22.93%\n",
      "üìä Evaluation Results for XGBoost:\n",
      " - RMSLE: 1.0750\n",
      " - RMSE: 41805.7023\n",
      " - Normalized RMSE: 4.66%\n",
      " - Relative Error: 23.08%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Evaluate\n",
    "        metrics = evaluate_model(model, X_val, y_val, target_scaler, model_name)\n",
    "        \n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "        input_example = X_val[:5] \n",
    "        # Log the model\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\", signature=signature, input_example=input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "15ff21f5-7661-48c6-93e4-37c57fc17f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation Results for RandomForestRegressor:\n",
      " - RMSLE: 0.3800\n",
      " - RMSE: 41066.4408\n",
      " - Normalized RMSE: 4.57%\n",
      " - Relative Error: 22.67%\n",
      "‚úÖ RandomForestRegressor logged to MLflow with best params.\n",
      "üìä Evaluation Results for XGBRegressor:\n",
      " - RMSLE: 1.1361\n",
      " - RMSE: 40188.8780\n",
      " - Normalized RMSE: 4.48%\n",
      " - Relative Error: 22.19%\n",
      "‚úÖ XGBRegressor logged to MLflow with best params.\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RandomForestRegressor\": GridSearchCV(\n",
    "        estimator=RandomForestRegressor(random_state=42),\n",
    "        param_grid={\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "        },\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"XGBRegressor\": GridSearchCV(\n",
    "        estimator=XGBRegressor(objective=\"reg:squarederror\", random_state=42),\n",
    "        param_grid={\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1],\n",
    "            \"max_depth\": [3, 6]\n",
    "        },\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for rfe_selection in range(10, 34):\n",
    "        \n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            model.fit(X_train, y_train)\n",
    "            best_model = model.best_estimator_\n",
    "            y_pred = best_model.predict(X_val)\n",
    "    \n",
    "            # Evaluate (your custom function)\n",
    "            metrics = evaluate_model(best_model, X_val, y_val, target_scaler, model_name)\n",
    "    \n",
    "            # Log best hyperparameters and metrics\n",
    "            mlflow.log_param(\"model_name\", model_name)\n",
    "            mlflow.log_params(model.best_params_)  # ‚Üê logs hyperparameters from GridSearchCV\n",
    "            mlflow.log_metrics(metrics)\n",
    "    \n",
    "            # Log model with signature and input example\n",
    "            signature = infer_signature(X_val, y_pred)\n",
    "            input_example = X_val[:5]\n",
    "            mlflow.sklearn.log_model(best_model, \"model\", signature=signature, input_example=input_example)\n",
    "    \n",
    "            print(f\"‚úÖ {model_name} logged to MLflow with best params.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f19325-3c3c-467a-90cf-473d8026614b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
